test_st     <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
test.s.tr    <- predict(tr_st, newdata = test_st)
cfusion.s.tr <- table(test.s.tr, test$Type)
error.s.tr   <- sum(test.s.tr != test$Type) / (nrow(df) - length(idx))
test.s.rf    <- predict(rf_st, newdata = test_st)
cfusion.s.rf <- table(test.s.rf, test$Type)
error.s.rf   <- sum(test.s.rf != test$Type) / (nrow(df) - length(idx))
test.s.xgb    <- predict(xgb_st, newdata = test_st)
cfusion.s.xgb <- table(test.s.xgb, test$Type)
error.s.xgb   <- sum(test.s.xgb != test$Type) / (nrow(df) - length(idx))
test.s.svm    <- predict(svm_st, newdata = test_st)
cfusion.s.svm <- table(test.s.svm, test$Type)
error.s.svm   <- sum(test.s.svm != test$Type) / (nrow(df) - length(idx))
test.s.mdl    <- predict(mdl_st, newdata = test_st)
cfusion.s.mdl <- table(test.s.mdl, test$Type)
error.s.mdl   <- sum(test.s.mdl != test$Type) / (nrow(df) - length(idx))
test.s.bag    <- predict(bag_st, newdata = test_st)
cfusion.s.bag <- table(test.s.bag, test$Type)
error.s.bag   <- sum(test.s.bag != test$Type) / (nrow(df) - length(idx))
best.res      <- 1 - min(error.e.tr, error.e.rf, error.e.xgb, error.e.svm.u, error.e.mdl, error.e.bag,
error.s.tr, error.s.rf, error.s.xgb, error.s.svm, error.s.mdl, error.s.bag)
best.res
test.result   <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test),
tr.s_predict = predict(tr_st, newdata = test_st),
rf.s_predict = predict(rf_st, newdata = test_st),
xgb.s_predict = predict(xgb_st, newdata = test_st),
svm.s_predict = predict(svm_st, newdata = test_st),
mdl.s_predict = predict(mdl_st, newdata = test_st),
bag.s_predict = predict(bag_st, newdata = test_st))
Confusion_Matrix  <- cfusion.s.xgb
Acc_Table         <- data.frame("Decision Tree" = 1 - error.e.tr,
"Random Forest" = 1 - error.e.rf,
"XGBoost"       = 1 - error.e.xgb,
"SVM"           = 1 - error.e.svm.u,
"MDL"           = 1 - error.e.mdl,
"Bagging"       = 1 - error.e.bag,
"Stacking_Tree" = 1 - error.s.tr,
"Stacking_RF"   = 1 - error.s.rf,
"Stacking_XGB"  = 1 - error.s.xgb,
"Stacking_SVM"  = 1 - error.s.svm,
"Stacking_MDL"  = 1 - error.s.mdl,
"Stacking_Bag"  = 1 - error.s.bag)
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.Rdata.RData")
# Result Table
Acc_Table
Acc_Table         <- t(data.frame("Decision Tree" = 1 - error.e.tr,
"Random Forest" = 1 - error.e.rf,
"XGBoost"       = 1 - error.e.xgb,
"SVM"           = 1 - error.e.svm.u,
"MDL"           = 1 - error.e.mdl,
"Bagging"       = 1 - error.e.bag,
"Stacking_Tree" = 1 - error.s.tr,
"Stacking_RF"   = 1 - error.s.rf,
"Stacking_XGB"  = 1 - error.s.xgb,
"Stacking_SVM"  = 1 - error.s.svm,
"Stacking_MDL"  = 1 - error.s.mdl,
"Stacking_Bag"  = 1 - error.s.bag))
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.Rdata.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB shows the least error rate
Acc_Table[which.max(Acc_Table)]
colnames(Acc_Table) <- "Accuracy"
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB shows the least error rate
Acc_Table[which.max(Acc_Table)]
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
# see the prediction
predict(xgb_st, test_st)
# see the actual value
test_st$Type
test
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
test[1,40] <- "지출결의서"
test[2,40] <- "계약서"
test[3,40] <- "근태신청ㅅ"
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
test_st$Type
# see the prediction
predict(xgb_st, test_st)
# see the actual value
test_st$Type
test[1,40]
test
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
test
ㅅㄷㄴㅅ[1,40]
test[1,40]
test[1,40] <- "지출결의서"
test[1,40]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
test_st$Type
test_st$Type
test[1,40] <- c("지출결의서")
test[1,40]
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
test
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB shows the least error rate
Acc_Table[which.max(Acc_Table)]
# Show the best result : Stack_XGB shows the least error rate
order(Acc_Table[which.max(Acc_Table)])
sort(Accuracy, decreasing = TRUE)
sort(Acc_Table, decreasing = TRUE)
Acc_Table         <- sort(Acc_Table, decreasing = TRUE)
Acc_Table
Acc_Table         <- sort(t(data.frame("Decision Tree" = 1 - error.e.tr,
"Random Forest" = 1 - error.e.rf,
"XGBoost"       = 1 - error.e.xgb,
"SVM"           = 1 - error.e.svm.u,
"MDL"           = 1 - error.e.mdl,
"Bagging"       = 1 - error.e.bag,
"Stacking_Tree" = 1 - error.s.tr,
"Stacking_RF"   = 1 - error.s.rf,
"Stacking_XGB"  = 1 - error.s.xgb,
"Stacking_SVM"  = 1 - error.s.svm,
"Stacking_MDL"  = 1 - error.s.mdl,
"Stacking_Bag"  = 1 - error.s.bag)), decreasing = TRUE)
Acc_Table
Acc_Table         <- t(sort(data.frame("Decision Tree" = 1 - error.e.tr,
"Random Forest" = 1 - error.e.rf,
"XGBoost"       = 1 - error.e.xgb,
"SVM"           = 1 - error.e.svm.u,
"MDL"           = 1 - error.e.mdl,
"Bagging"       = 1 - error.e.bag,
"Stacking_Tree" = 1 - error.s.tr,
"Stacking_RF"   = 1 - error.s.rf,
"Stacking_XGB"  = 1 - error.s.xgb,
"Stacking_SVM"  = 1 - error.s.svm,
"Stacking_MDL"  = 1 - error.s.mdl,
"Stacking_Bag"  = 1 - error.s.bag), decreasing = TRUE))
Acc_Table
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
colnames(Acc_Table) <- "Accuracy"
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
# 1.Experiment  : Train 0.8 // Test : 0.2
####################################################################################################
# Dataset
View(df)
# Result Table
Acc_Table
# Show the best result : Stack_XGB, Random Forest and MDL show the highest accuracy
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
result
Doc_predict <- function(folder_list = folder_list){
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
return(result)
}
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
Doc_predict <- function(folder_list = folder_list){
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
return(result)
}
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
####################################################################################################
# 1.Experiment  : Train 0.8 // Test : 0.2
####################################################################################################
# Dataset
View(df)
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
# 1.Experiment  : Train 0.8 // Test : 0.2
####################################################################################################
# Dataset
View(df)
# Result Table
Acc_Table
# Show the best result : Stack_XGB, Random Forest and MDL show the highest accuracy
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB, Random Forest and MDL show the highest accuracy
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# Document Prediction Function
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
