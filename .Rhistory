rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
test      <- dtm.all[,-41]
rm(test)
View(dtm.all)
test      <- dtm.all[,-1]
test_st     <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
View(df)
View(test)
test      <- df[-3,]
test_st     <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
colnames(df)
colnames(dtm.all[,-1])
order(df)
order(df[,40])
order(colnames(df))
order(colnames(test))
test_st     <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
rm(test)
Path
colnames(dtm.all[,-1])
colnames(df)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# Remove whole values
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# Dataframe which contains information of each text data's TF-IDF
load("DCS.RData")
####################################################################################################
# 1.Experiment with all classes : Train 0.8 // Test : 0.2
####################################################################################################
# contain all claases' data and results of several algorithms
load("DCS_AllClasses.Rdata")
# Result Table
Error_Table
# Show the best result
#Stack_XGB shows the least error rate
Error_Table[which.min(Error_Table)]
# Show the confusion matrix
cfusion.s.xgb  #'회의록' class can be removed
####################################################################################################
# 2.Experiment without '회의록' class : Train 0.8 // Test : 0.2
####################################################################################################
rm(list=ls())
load("DCS_ClassRemoved.Rdata")
# Result Table
Error_Table2
# Show the best result
Error_Table2[which.min(Error_Table2)] #Stack_XGB shows the least error rate
# Show the confusion matrix
cfusion.s.xgb
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
rm(list=ls())
order(df)[[1]]
order(df)[1]
order(df)
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df          <- rbind(df, tmp)
}
df$doc_id <- 1:NROW(df)
df        <- df %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df        <- create_dtm(df)
df        <- df[, -1]
df
order(df)[1]
order(df)[2]
order(df)[3]
order(df)
order(colnanmes(df))[1]
order(colnames(df))
order(colnames(df))[1]
colnames(dtm.all)
colnames(dtm.all[ ,-1])
colnames(df)
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
# remove the rdata history
rm(list=ls())
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp          <- rbind(df.tmp, tmp)
}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
df.tmp
order(dtm.all[,-1])
order(colanames(dtm.all[,-1]))
order(colnames(dtm.all[,-1]))
order(colnames(dtm.all[,-1]))[1]
x <- data.frame()
for(i in 1:40){
x <- cbind(x, which(colnames(df.tmp)) == colnames(dtm.all[, i]))
}
colnames(df.tmp)
x <- data.frame()
for(i in 1:40){
x <- cbind(x, which(colnames(df.tmp) == colnames(dtm.all[, i])))
}
df <- df.tmp[ ,x]
x
# rearrange the column of df.tmp
for(i in 1:ncol(df.tmp)){
df[, i] <- df[, order(colnames(df))[i]]
}
df
test_st
# rearrange the column of df.tmp
for(i in 1:ncol(df.tmp)){
df[, i] <- df.tmp[, order(colnames(df))[i]]
}
ncol(df.tmp)
# rearrange the column of df.tmp
for(i in 1:ncol(df.tmp)){
df[, i] <- df.tmp[, order(colnames(df))[i]]
}
df
View(df)
rm(df)
test_st     <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
predict(xgb_st, df[,-40])
predict(xgb_st, test_st)
df.tmp
test <- df.tmp
test_st     <- data.frame(Type = test$Type,
tr_predict = predict(dt_fit, newdata = test),
rf_predict = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
# remove the rdata history
rm(list=ls())
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp          <- rbind(df.tmp, tmp)
}
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp %>% select(Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
View(df.tmp)
View(df.tmp)
df.tmp        <- df.tmp[, -1]
test <- df.tmp[,c(1:11,40)]
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
View(df.tmp)
# rearrange the column of df.tmp
for(i in 1:ncol(df.tmp)){
df.tmp[, order(colnames(df.tmp))[i]]
}
# rearrange the column of df.tmp
for(i in 1:ncol(df.tmp)){
df[,i] <- df.tmp[, order(colnames(df.tmp))[i]]
}
# rearrange the column of df.tmp
df <- data.frame
# rearrange the column of df.tmp
df <- data.frame()
for(i in 1:ncol(df.tmp)){
df[,i] <- cbind(df, df.tmp[, order(colnames(df.tmp))[i]])
}
x <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){
x <- cbind(x, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i]))
}
df <- df.tmp[ ,x]
colnames(df)
colnames(dtm.all[,-1])
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
test <- df.tmp[ ,x]
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
predict(xgb_st, test_st)
test_st$Type
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
# remove the rdata history
rm(list=ls())
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)
}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
df.tmp
x <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){
x <- cbind(x, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i]))
}
test <- df.tmp[ ,x]
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
predict(xgb_st, test_st)
test_st$Type
predict(xgb_st, test_st) == test_st$Type
predict(xgb_st, test_st)
test_st$Type
table(predict(xgb_st, test_st) , test_st$Type)
predict(xgb_st, test_st)
test_st$Type
test_st
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
x <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ x <- cbind(x, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, x]
test
predict(xgb_st, test_st)
test_st$Type
# set df.tmp as test data
test <- df.tmp[, x]
# Result Table
Error_Table
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
predict(xgb_st, test_st)
test_st$Type
# see the result of predict
prediction <- predict(xgb_st, test_st)
test_st$Type == prediction
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
# remove the rdata history
rm(list=ls())
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
x <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ x <- cbind(x, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, x]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
# see the result of predict
predict(xgb_st, test_st)
test_st$Type
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
# remove the rdata history
rm(list=ls())
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
# see the result of predict
predict(xgb_st, test_st)
test_st$Type
xgb_st$results
xgb_st$pred
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071")
sapply(pkgs, require, character.only = TRUE)
# Dataframe which contains information of each text data's TF-IDF
load("DCS.RData")
####################################################################################################
# 1.Experiment with all classes : Train 0.8 // Test : 0.2
####################################################################################################
# contain all claases' data and results of several algorithms
load("DCS_AllClasses.Rdata")
# Result Table
Error_Table
# Show the best result
#Stack_XGB shows the least error rate
Error_Table[which.min(Error_Table)]
# Show the confusion matrix
cfusion.s.xgb  #'회의록' class can be removed
####################################################################################################
# 2.Experiment without '회의록' class : Train 0.8 // Test : 0.2
####################################################################################################
# remove the rdata history
rm(list=ls())
load("DCS_ClassRemoved.Rdata")
# Result Table
Error_Table2
# Show the best result
Error_Table2[which.min(Error_Table2)] #Stack_XGB shows the least error rate
# Show the best result
#Stack_XGB shows the least error rate
Error_Table2[which.min(Error_Table2)]
# Show the confusion matrix
cfusion.s.xgb
####################################################################################################
# 3.Load the text data and predict
####################################################################################################
# remove the rdata history
rm(list=ls())
# load the best algorithm : Stak_XGB
load("DCS_AllClasses.Rdata")
# Root folder path
root_folder  <- "./문서"
# Folder list(Group by each document type)
folder_list  <- list.files(root_folder)
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
# see the prediction
predict(xgb_st, test_st)
# see the actual value
test_st$Type
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
