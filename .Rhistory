test <- d.t[1, ]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
return(result)
}
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder  <- folder_list_tmp[3]
Doc_predict(folder_list)
Doc_predict <- function(folder_list = folder_list){
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
d.t  <- dtm.all[, -1]
tmp  <- test
a    <- data.frame()
for (i in 1:ncol(tmp)) {if(tmp[ , i]!=0){a <- c(a, i)}}
for(j in 1:(ncol(d.t)-1)){
if (j %in% a) {d.t <- d.t[which(d.t[, j]!= 0), ]}
else          {d.t <- d.t[which(d.t[, j]== 0), ]}
}
test <- d.t[1, ]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
return(result)
}
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
Doc_predict <- function(folder_list = folder_list){
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
d.t  <- dtm.all[, -1]
tmp  <- test
a    <- data.frame()
for (i in 1:ncol(tmp)) {if(tmp[ , i]!=0){a <- c(a, i)}}
for(j in 1:(ncol(d.t)-1)){
if (j %in% a) {d.t <- d.t[which(d.t[, j]!= 0), ]}
else          {d.t <- d.t[which(d.t[, j]== 0), ]}
}
test <- d.t[1, ]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
return(result)
}
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
# 1.Experiment  : 5-fold cross validation
####################################################################################################
# Dataset
View(df)
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
# 1.Experiment  : 5-fold cross validation
####################################################################################################
# Dataset
View(df)
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
save.image("C:/Users/Wayne/Desktop/NIPA_TestCase/DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
### Document prediction function
####################################################################################################
Doc_predict <- function(folder_list = folder_list){
# train data frame
df.tmp <- data.frame()
for (i in 1:NROW(folder_list)){
folder_path <- paste0(root_folder, "/", folder_list[i], "/")
tmp         <- get_folder_info(folder_path)
df.tmp      <- rbind(df.tmp, tmp)}
df.tmp$doc_id <- 1:NROW(df.tmp)
df.tmp        <- df.tmp %>% select(doc_id, Path, Type, Name, Extension, text)
# Create the document term matrix and Remove the doc_id column
df.tmp        <- create_dtm(df.tmp)
df.tmp        <- df.tmp[, -1]
# rearrange the column of df.tmp to equalize with dtm.all
order <- which(colnames(df.tmp) == colnames(dtm.all[,-1])[1])
for(i in 2:40){ order <- cbind(order, which(colnames(df.tmp) == colnames(dtm.all[,-1])[i])) }
# set df.tmp as test data
test <- df.tmp[, order]
d.t  <- dtm.all[, -1]
tmp  <- test
a    <- data.frame()
for (i in 1:ncol(tmp)) {if(tmp[ , i]!=0){a <- c(a, i)}}
for(j in 1:(ncol(d.t)-1)){
if (j %in% a) {d.t <- d.t[which(d.t[, j]!= 0), ]}
else          {d.t <- d.t[which(d.t[, j]== 0), ]}
}
test <- d.t[1, ]
# load the result of Stack_XGB
test_st     <- data.frame(Type        = test$Type,
tr_predict  = predict(dt_fit, newdata = test),
rf_predict  = predict(rf_fit2, newdata = test),
xgb_predict = predict(xgb_fit, newdata = test),
svm_predict = predict(tuned.svm, newdata = test),
mdl_predict = predict(mdl_fit, newdata = test),
bag_predict = predict(bag_fit, newdata = test))
result <- list(Prediction = predict(xgb_st, test_st),
Actual     = test_st$Type)
return(result)
}
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 0.Setting up environment
####################################################################################################
# remove the rdata history
rm(list=ls())
# Install and Load the packages that are needed in experiments
pkgs <- c("caret", "dplyr", "rpart", "adabag", "randomForest", "e1071", "xgboost",
"dplyr", "officer", "pdftools", "stringr", "openxlsx", "tm")
sapply(pkgs, require, character.only = TRUE)
# load the text preprocessing functions
source("DCS_function.R", encoding = "UTF-8")
# rdata that contains result
load("DCS_result.RData")
####################################################################################################
# 1.Experiment  : 5-fold cross validation
####################################################################################################
# Dataset
View(df)
# Result Table
Acc_Table
# Show the best result : Stack_XGB
Acc_Table[which.max(Acc_Table)]
# Show the confusion matrix
Confusion_Matrix
# Show the confusion matrix
Confusion_Matrix
####################################################################################################
# 2.Load the text data and predict
####################################################################################################
# Root folder path
root_folder  <- "./Folder"
# Folder list (the number of input data texts is 3)
folder_list_tmp  <- list.files(root_folder)
# First document prediction
folder_list  <- folder_list_tmp[1]
Doc_predict(folder_list)
# Second document prediction
folder_list  <- folder_list_tmp[2]
Doc_predict(folder_list)
# Last document prediction
folder_list  <- folder_list_tmp[3]
Doc_predict(folder_list)
